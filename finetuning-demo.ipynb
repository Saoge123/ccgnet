{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccgnet import experiment as exp\n",
    "from ccgnet.finetune import *\n",
    "from ccgnet import layers\n",
    "from ccgnet.layers import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from ccgnet.Dataset import Dataset, DataLoader\n",
    "from ccgnet.finetune import Finetuning\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1 = Dataset('data/CC_Table/ECC_Table.tab', mol_blocks_dir='data/Mol_Blocks.dir')\n",
    "data1.make_graph_dataset(Desc=1, A_type='OnlyCovalentBond', hbond=0, pipi_stack=0, contact=0, make_dataframe=True, max_graph_size=160)\n",
    "data2 = Dataset('data/CC_Table/ECC_Table-DataAug.tab', mol_blocks_dir='data/Mol_Blocks.dir')\n",
    "data2.make_graph_dataset(Desc=1, A_type='OnlyCovalentBond', hbond=0, pipi_stack=0, contact=0, make_dataframe=True, max_graph_size=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl20_test = eval(open('data/Test/Test_Samples/CL-20_Test.list').read())\n",
    "tnt_test = eval(open('data/Test/Test_Samples/TNT_Test.list').read())\n",
    "cv_set = eval(open('data/ECC_Finetuning_Set.list').read())   # The negative samples in this ECC set was randomly selected from the data/MEPS.csv, which was used in our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCGNet(object):\n",
    "    def build_model(self, inputs, is_training, global_step):\n",
    "        V = inputs[0]\n",
    "        A = inputs[1]\n",
    "        labels = inputs[2]\n",
    "        mask = inputs[3]\n",
    "        graph_size = inputs[4]\n",
    "        tags = inputs[5]\n",
    "        global_state = inputs[6]\n",
    "        subgraph_size = inputs[7]\n",
    "        # message passing \n",
    "        V, global_state = CCGBlock(V, A, global_state, subgraph_size, no_filters=64, mask=mask, num_updates=global_step, is_training=is_training)\n",
    "        V, global_state = CCGBlock(V, A, global_state, subgraph_size, no_filters=16, mask=mask, num_updates=global_step, is_training=is_training)\n",
    "        V, global_state = CCGBlock(V, A, global_state, subgraph_size, no_filters=64, mask=mask, num_updates=global_step, is_training=is_training)\n",
    "        V, global_state = CCGBlock(V, A, global_state, subgraph_size, no_filters=16, mask=mask, num_updates=global_step, is_training=is_training)\n",
    "        # readout\n",
    "        V = ReadoutFunction(V, global_state, graph_size, num_head=2, is_training=is_training)\n",
    "        # predict\n",
    "        with tf.compat.v1.variable_scope('Predictive_FC_1') as scope:\n",
    "            V = layers.make_embedding_layer(V, 256)\n",
    "            V = layers.make_bn(V, is_training, mask=None, num_updates=global_step)\n",
    "            V = tf.nn.relu(V)\n",
    "            V = tf.compat.v1.layers.dropout(V, 0.457, training=is_training)\n",
    "        with tf.compat.v1.variable_scope('Predictive_FC_2') as scope:\n",
    "            V = layers.make_embedding_layer(V, 1024)\n",
    "            V = layers.make_bn(V, is_training, mask=None, num_updates=global_step)\n",
    "            V = tf.nn.relu(V)\n",
    "            V = tf.compat.v1.layers.dropout(V, 0.457, training=is_training)\n",
    "        with tf.compat.v1.variable_scope('Predictive_FC_3') as scope:\n",
    "            V = layers.make_embedding_layer(V, 256)\n",
    "            V = layers.make_bn(V, is_training, mask=None, num_updates=global_step)\n",
    "            V = tf.nn.relu(V)\n",
    "            V = tf.compat.v1.layers.dropout(V, 0.457, training=is_training)\n",
    "        out = layers.make_embedding_layer(V, 2, name='final')\n",
    "        return out, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "restore_path = './snapshot/CCGNet/CC_Dataset/*/'\n",
    "for p in glob.glob(restore_path):\n",
    "    restore_file = tf.train.latest_checkpoint(p)\n",
    "    random.shuffle(cv_set)\n",
    "    cv_samples = np.array(cv_set)\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    fold_5 = {}\n",
    "    n = 0\n",
    "    for train_ix,test_ix in kf.split(cv_samples):\n",
    "        fold_5['fold-{}'.format(n)] = {}\n",
    "        fold_5['fold-{}'.format(n)]['train'] = cv_samples[train_ix]\n",
    "        fold_5['fold-{}'.format(n)]['valid'] = cv_samples[test_ix]\n",
    "        n += 1\n",
    "    dataset_name = 'ECC-'+p.split('/')[-2][-1]\n",
    "    snapshot_path = 'finetuning_snapshot'\n",
    "    model_name = 'CCGNet'\n",
    "    for fold in ['fold-{}'.format(i) for i in range(5)]:\n",
    "        print('\\n################ {} ################'.format(fold))\n",
    "        train_data1, valid_data1, test_data1 = data1.split(train_samples=fold_5[fold]['train'], \n",
    "                                                     valid_samples=fold_5[fold]['valid'], with_test=True, \n",
    "                                                     test_samples=list(set(cl20_test+tnt_test)))\n",
    "        train_data2, valid_data2, test_data2 = data2.split(train_samples=fold_5[fold]['train'], \n",
    "                                                     valid_samples=fold_5[fold]['valid'], with_test=True, \n",
    "                                                     test_samples=list(set(cl20_test+tnt_test)))\n",
    "        train_data = []\n",
    "        for ix, i in enumerate(train_data1):\n",
    "            train_data.append(np.concatenate([i, train_data2[ix]]))\n",
    "        tf.reset_default_graph()\n",
    "        model = CCGNet()\n",
    "        model = Finetuning(model, train_data, valid_data1, with_test=True, test_data=test_data1, snapshot_path=snapshot_path, use_subgraph=True,\n",
    "                           restore_file=restore_file, model_name=model_name, dataset_name=dataset_name+'/time_{}'.format(fold[-1]),\n",
    "                           remove_keywords=['Predictive_FC_3', 'final'])\n",
    "        history = model.fit(save_info=True, save_att=True, silence=0, \n",
    "                            metric='loss', early_stop=0, early_stop_cutoff=20)\n",
    "    end = time.time()\n",
    "    time_gap = end-start\n",
    "    h = time_gap//3600\n",
    "    h_m = time_gap%3600\n",
    "    m = h_m//60\n",
    "    s = h_m%60\n",
    "    print('{}h {}m {}s'.format(int(h),int(m),round(s,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccgnet.parselog import ParseTestLog, ParseTestLogEnsemble, get_info\n",
    "import glob\n",
    "\n",
    "\n",
    "PATH = glob.glob('{}/{}/*'.format(snapshot_path,model_name))\n",
    "ENS = []\n",
    "for i in PATH:\n",
    "    print('#### '+i.split('/')[-1]+' ####')\n",
    "    val_list_ = glob.glob(i+'/*/*val*')\n",
    "    ens_ = ParseTestLogEnsemble([ParseTestLog(j) for j in val_list_])\n",
    "    ens_.Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccgnet.parselog import ParseValidLog\n",
    "\n",
    "val_list = glob.glob('{}/{}/*/*'.format(snapshot_path,model_name))\n",
    "l = []\n",
    "for i in val_list:\n",
    "    l.append(ParseValidLog(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_log(p):\n",
    "    length = len(p.split('/'))\n",
    "    l = p.split('/')[:length-1]\n",
    "    l.append('/model-val-info.txt')\n",
    "    return '/'.join(l)\n",
    "best10 = [get_test_log(i[1]) for i in sorted([(i.loss, i.logfile) for i in l])[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = ParseTestLogEnsemble([ParseTestLog(i) for i in best10])\n",
    "print('####### Mean ########')\n",
    "ens.Reports\n",
    "print('####### Bagging ########')\n",
    "ens_bagging = ens.Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccgnet.parselog import TestAccForEachMol\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dic = {}\n",
    "#print('\\n######## TNT  ########')\n",
    "tnt_bagging = TestAccForEachMol(tnt_test, best10, is_return=1, is_print=0)\n",
    "dic['TNT'] = tnt_bagging[1]\n",
    "#print('\\n######## CL-20  ########')\n",
    "cl20_bagging = TestAccForEachMol(cl20_test, best10, is_return=1, is_print=0)\n",
    "dic['CL-20'] = cl20_bagging[1]\n",
    "pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(CCDC)",
   "language": "python",
   "name": "ccdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
