{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from ccgnet import experiment as exp\n",
    "from ccgnet import layers\n",
    "from ccgnet.layers import *\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from ccgnet.Dataset import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [16:43:24] UFFTYPER: Unrecognized charge state for atom: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad input sample:DAQVAS, skipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [16:43:51] UFFTYPER: Unrecognized charge state for atom: 0\n",
      "RDKit WARNING: [16:43:54] UFFTYPER: Warning: hybridization set to SP3 for atom 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad input sample:995&77245, skipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [16:44:17] UFFTYPER: Warning: hybridization set to SP3 for atom 0\n",
      "RDKit WARNING: [16:44:17] UFFTYPER: Warning: hybridization set to SP3 for atom 0\n",
      "RDKit WARNING: [16:44:18] UFFTYPER: Warning: hybridization set to SP3 for atom 0\n",
      "RDKit WARNING: [16:44:18] UFFTYPER: Warning: hybridization set to SP3 for atom 0\n",
      "RDKit WARNING: [16:44:38] UFFTYPER: Warning: hybridization set to SP3 for atom 0\n",
      "RDKit ERROR: [16:45:08] UFFTYPER: Unrecognized charge state for atom: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad input sample:NEZROZ, skipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [16:45:17] UFFTYPER: Warning: hybridization set to SP3 for atom 0\n",
      "RDKit ERROR: [16:45:20] UFFTYPER: Unrecognized charge state for atom: 0\n",
      "RDKit ERROR: [16:45:20] UFFTYPER: Unrecognized charge state for atom: 14\n",
      "RDKit ERROR: [16:45:44] UFFTYPER: Unrecognized charge state for atom: 0\n",
      "RDKit WARNING: [16:45:48] UFFTYPER: Warning: hybridization set to SP3 for atom 5\n",
      "RDKit WARNING: [16:45:54] UFFTYPER: Warning: hybridization set to SP3 for atom 3\n",
      "RDKit WARNING: [16:45:54] UFFTYPER: Warning: hybridization set to SP3 for atom 3\n",
      "RDKit ERROR: [16:46:04] UFFTYPER: Unrecognized atom type: S_5+6 (0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 202.75 s\n"
     ]
    }
   ],
   "source": [
    "data = Dataset('./data/CC_Table.tab', mol_blocks_dir='./data/Mol_Blocks.dir')\n",
    "data.make_graph_dataset(Desc=1, A_type='OnlyCovalentBond', save_name='CC_Dataset_OB.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader('CC_Dataset_OB.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "test = np.array(eval(open('./data/Test_set.list').read()))\n",
    "cv = np.array([i for i in data.dataframe.keys() if i not in test])\n",
    "np.random.shuffle(cv)\n",
    "fold_10 = {}\n",
    "fold_10['test'] = test\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1000)\n",
    "n = 0\n",
    "for train_idx, test_idx in kf.split(cv):\n",
    "    fold = 'fold-{}'.format(n)\n",
    "    fold_10[fold] = {}\n",
    "    fold_10[fold]['train'] = cv[train_idx]\n",
    "    fold_10[fold]['valid'] = cv[test_idx]\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCGNet(object):\n",
    "    def build_model(self, inputs, is_training, global_step):\n",
    "        V = inputs[0]\n",
    "        A = inputs[1]\n",
    "        labels = inputs[2]\n",
    "        mask = inputs[3]\n",
    "        graph_size = inputs[4]\n",
    "        tags = inputs[5]\n",
    "        global_state = inputs[6]\n",
    "        subgraph_size = inputs[7]\n",
    "        \n",
    "        global_state = tf.reshape(global_state, [-1, int(global_state.get_shape()[-1].value/2)])\n",
    "        V, global_state = CCGBlock(V, A, global_state, subgraph_size, no_filters=128, mask=mask, num_updates=global_step, is_training=is_training)\n",
    "        V, global_state = CCGBlock(V, A, global_state, subgraph_size, no_filters=64, mask=mask, num_updates=global_step, is_training=is_training)\n",
    "        V, global_state = CCGBlock(V, A, global_state, subgraph_size, no_filters=64, mask=mask, num_updates=global_step, is_training=is_training)\n",
    "        V, global_state = CCGBlock(V, A, global_state, subgraph_size, no_filters=32, mask=mask, num_updates=global_step, is_training=is_training)\n",
    "        V, global_state = CCGBlock(V, A, global_state, subgraph_size, no_filters=16, mask=mask, num_updates=global_step, is_training=is_training)\n",
    "        V = layers.multi_head_global_attention(V, graph_size, num_head=10)\n",
    "        global_state = tf.reshape(global_state, [-1, 32])\n",
    "        V = tf.concat([V, global_state], 1)\n",
    "        V = layers.make_embedding_layer(V, 256, name='FC')\n",
    "        V = layers.make_bn(V, is_training, mask=None, num_updates=global_step)\n",
    "        V = tf.nn.relu(V)\n",
    "        out = layers.make_embedding_layer(V, 2, name='final')\n",
    "        prob = layers.make_softmax_layer(out, axis=1, name=None)\n",
    "        return out, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################ fold-0 ################\n",
      "WARNING:tensorflow:From /export/home/jyy/CCGNet-Openbabel/ccgnet/layers.py:69: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /export/home/jyy/CCGNet-Openbabel/ccgnet/layers.py:71: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /export/home/jyy/CCGNet-Openbabel/ccgnet/layers.py:71: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /export/home/jyy/CCGNet-Openbabel/ccgnet/experiment.py:124: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "Creating loss function and summaries\n",
      "Preparing training\n",
      "WARNING:tensorflow:From /export/home/jyy/anaconda3/envs/ccdc/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:277: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/jyy/anaconda3/envs/ccdc/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/export/home/jyy/anaconda3/envs/ccdc/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting summaries\n",
      "## Epoch 0 ==> Train Loss:0.19732, Train Acc:93.12, Test Loss:0.09167, Test Acc:96.88, Elapsed Time:32.31 s\n",
      "## Epoch 1 ==> Train Loss:0.07867, Train Acc:97.28, Test Loss:0.07416, Test Acc:97.27, Elapsed Time:16.76 s\n",
      "## Epoch 2 ==> Train Loss:0.06458, Train Acc:97.58, Test Loss:0.08490, Test Acc:96.49, Elapsed Time:15.67 s\n",
      "## Epoch 3 ==> Train Loss:0.08735, Train Acc:97.19, Test Loss:0.04794, Test Acc:98.31, Elapsed Time:16.37 s\n",
      "## Epoch 4 ==> Train Loss:0.05823, Train Acc:98.12, Test Loss:0.03860, Test Acc:98.83, Elapsed Time:16.00 s\n",
      "## Epoch 5 ==> Train Loss:0.04632, Train Acc:98.03, Test Loss:0.04546, Test Acc:98.44, Elapsed Time:15.69 s\n",
      "## Epoch 6 ==> Train Loss:0.07339, Train Acc:97.39, Test Loss:0.06752, Test Acc:98.31, Elapsed Time:15.81 s\n",
      "## Epoch 7 ==> Train Loss:0.05109, Train Acc:98.16, Test Loss:0.03601, Test Acc:98.70, Elapsed Time:15.80 s\n",
      "## Epoch 8 ==> Train Loss:0.04884, Train Acc:98.24, Test Loss:0.05227, Test Acc:97.79, Elapsed Time:15.72 s\n",
      "## Epoch 9 ==> Train Loss:0.02443, Train Acc:99.32, Test Loss:0.04045, Test Acc:98.44, Elapsed Time:15.60 s\n",
      "## Epoch 10 ==> Train Loss:0.02574, Train Acc:99.08, Test Loss:0.02978, Test Acc:99.09, Elapsed Time:16.65 s\n",
      "## Epoch 11 ==> Train Loss:0.04672, Train Acc:98.36, Test Loss:0.05470, Test Acc:97.92, Elapsed Time:15.77 s\n",
      "## Epoch 12 ==> Train Loss:0.04084, Train Acc:98.40, Test Loss:0.04268, Test Acc:98.44, Elapsed Time:15.37 s\n",
      "## Epoch 13 ==> Train Loss:0.05188, Train Acc:98.11, Test Loss:0.06818, Test Acc:97.01, Elapsed Time:15.53 s\n",
      "## Epoch 14 ==> Train Loss:0.04991, Train Acc:98.11, Test Loss:0.05840, Test Acc:97.53, Elapsed Time:15.69 s\n",
      "## Epoch 15 ==> Train Loss:0.04233, Train Acc:98.58, Test Loss:0.05507, Test Acc:98.44, Elapsed Time:15.31 s\n",
      "## Epoch 16 ==> Train Loss:0.02045, Train Acc:99.22, Test Loss:0.03056, Test Acc:99.09, Elapsed Time:16.18 s\n",
      "WARNING:tensorflow:From /export/home/jyy/anaconda3/envs/ccdc/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "## Epoch 17 ==> Train Loss:0.03201, Train Acc:98.93, Test Loss:0.04114, Test Acc:99.22, Elapsed Time:16.19 s\n",
      "## Epoch 18 ==> Train Loss:0.02700, Train Acc:98.87, Test Loss:0.03735, Test Acc:98.96, Elapsed Time:16.01 s\n",
      "## Epoch 19 ==> Train Loss:0.02118, Train Acc:99.15, Test Loss:0.03033, Test Acc:99.35, Elapsed Time:16.20 s\n",
      "## Epoch 20 ==> Train Loss:0.02801, Train Acc:99.25, Test Loss:0.02700, Test Acc:99.09, Elapsed Time:15.53 s\n",
      "## Epoch 21 ==> Train Loss:0.03615, Train Acc:98.69, Test Loss:0.07137, Test Acc:98.18, Elapsed Time:15.80 s\n",
      "## Epoch 22 ==> Train Loss:0.02669, Train Acc:99.12, Test Loss:0.04752, Test Acc:98.83, Elapsed Time:15.61 s\n",
      "## Epoch 23 ==> Train Loss:0.01452, Train Acc:99.54, Test Loss:0.03634, Test Acc:99.22, Elapsed Time:15.74 s\n",
      "## Epoch 24 ==> Train Loss:0.01742, Train Acc:99.40, Test Loss:0.03704, Test Acc:98.96, Elapsed Time:15.19 s\n",
      "## Epoch 25 ==> Train Loss:0.02468, Train Acc:99.03, Test Loss:0.06283, Test Acc:98.57, Elapsed Time:15.80 s\n",
      "## Epoch 26 ==> Train Loss:0.02340, Train Acc:99.07, Test Loss:0.03755, Test Acc:98.83, Elapsed Time:15.72 s\n",
      "## Epoch 27 ==> Train Loss:0.01444, Train Acc:99.38, Test Loss:0.04535, Test Acc:98.44, Elapsed Time:15.37 s\n",
      "## Epoch 28 ==> Train Loss:0.01830, Train Acc:99.37, Test Loss:0.05625, Test Acc:98.44, Elapsed Time:15.87 s\n",
      "## Epoch 29 ==> Train Loss:0.02231, Train Acc:99.52, Test Loss:0.04730, Test Acc:98.70, Elapsed Time:15.65 s\n",
      "## Epoch 30 ==> Train Loss:0.01951, Train Acc:99.39, Test Loss:0.08191, Test Acc:97.40, Elapsed Time:15.89 s\n",
      "## Epoch 31 ==> Train Loss:0.01071, Train Acc:99.72, Test Loss:0.06274, Test Acc:98.05, Elapsed Time:15.76 s\n",
      "## Epoch 32 ==> Train Loss:0.01962, Train Acc:99.60, Test Loss:0.04486, Test Acc:99.09, Elapsed Time:16.10 s\n",
      "## Epoch 33 ==> Train Loss:0.04173, Train Acc:98.61, Test Loss:0.15431, Test Acc:96.88, Elapsed Time:15.34 s\n",
      "## Epoch 34 ==> Train Loss:0.03426, Train Acc:98.67, Test Loss:0.08687, Test Acc:97.66, Elapsed Time:15.96 s\n",
      "## Epoch 35 ==> Train Loss:0.01599, Train Acc:99.31, Test Loss:0.04292, Test Acc:98.70, Elapsed Time:16.17 s\n",
      "## Epoch 36 ==> Train Loss:0.02055, Train Acc:99.17, Test Loss:0.06609, Test Acc:98.70, Elapsed Time:15.59 s\n",
      "## Epoch 37 ==> Train Loss:0.05336, Train Acc:98.51, Test Loss:0.10160, Test Acc:97.92, Elapsed Time:15.51 s\n",
      "## Epoch 38 ==> Train Loss:0.03362, Train Acc:98.87, Test Loss:0.05524, Test Acc:98.70, Elapsed Time:15.91 s\n",
      "## Epoch 39 ==> Train Loss:0.01586, Train Acc:99.46, Test Loss:0.04110, Test Acc:98.70, Elapsed Time:16.19 s\n",
      "## Epoch 40 ==> Train Loss:0.01039, Train Acc:99.75, Test Loss:0.03700, Test Acc:98.83, Elapsed Time:15.54 s\n",
      "## Epoch 41 ==> Train Loss:0.02942, Train Acc:99.13, Test Loss:0.04907, Test Acc:98.31, Elapsed Time:15.61 s\n",
      "## Epoch 42 ==> Train Loss:0.04625, Train Acc:98.48, Test Loss:0.09345, Test Acc:96.49, Elapsed Time:15.56 s\n",
      "## Epoch 43 ==> Train Loss:0.03282, Train Acc:98.71, Test Loss:0.11545, Test Acc:96.23, Elapsed Time:16.01 s\n",
      "## Epoch 44 ==> Train Loss:0.05582, Train Acc:98.51, Test Loss:0.10207, Test Acc:97.53, Elapsed Time:15.39 s\n",
      "## Epoch 45 ==> Train Loss:0.02902, Train Acc:98.94, Test Loss:0.09185, Test Acc:98.57, Elapsed Time:15.65 s\n",
      "## Epoch 46 ==> Train Loss:0.01611, Train Acc:99.40, Test Loss:0.07535, Test Acc:97.92, Elapsed Time:15.81 s\n",
      "## Epoch 47 ==> Train Loss:0.01313, Train Acc:99.61, Test Loss:0.07105, Test Acc:97.92, Elapsed Time:16.02 s\n",
      "## Epoch 48 ==> Train Loss:0.01870, Train Acc:99.47, Test Loss:0.04749, Test Acc:98.83, Elapsed Time:15.77 s\n",
      "## Epoch 49 ==> Train Loss:0.03810, Train Acc:98.87, Test Loss:0.06636, Test Acc:97.53, Elapsed Time:15.62 s\n",
      "## Epoch 50 ==> Train Loss:0.02084, Train Acc:99.13, Test Loss:0.04741, Test Acc:97.92, Elapsed Time:15.61 s\n",
      "## Epoch 51 ==> Train Loss:0.01728, Train Acc:99.41, Test Loss:0.04166, Test Acc:99.09, Elapsed Time:15.43 s\n",
      "## Epoch 52 ==> Train Loss:0.01370, Train Acc:99.39, Test Loss:0.03940, Test Acc:98.96, Elapsed Time:15.36 s\n",
      "## Epoch 53 ==> Train Loss:0.01894, Train Acc:99.44, Test Loss:0.07955, Test Acc:98.31, Elapsed Time:15.49 s\n",
      "## Epoch 54 ==> Train Loss:0.01548, Train Acc:99.43, Test Loss:0.05151, Test Acc:98.96, Elapsed Time:15.77 s\n",
      "## Epoch 55 ==> Train Loss:0.02881, Train Acc:98.91, Test Loss:0.05533, Test Acc:98.05, Elapsed Time:15.63 s\n",
      "## Epoch 56 ==> Train Loss:0.05160, Train Acc:98.60, Test Loss:0.05564, Test Acc:97.66, Elapsed Time:15.74 s\n",
      "## Epoch 57 ==> Train Loss:0.08385, Train Acc:97.47, Test Loss:0.08713, Test Acc:97.40, Elapsed Time:14.95 s\n",
      "## Epoch 58 ==> Train Loss:0.06109, Train Acc:97.82, Test Loss:0.09619, Test Acc:97.40, Elapsed Time:15.51 s\n",
      "## Epoch 59 ==> Train Loss:0.02389, Train Acc:99.29, Test Loss:0.08056, Test Acc:97.40, Elapsed Time:15.35 s\n",
      "## Epoch 60 ==> Train Loss:0.02544, Train Acc:99.28, Test Loss:0.06608, Test Acc:97.66, Elapsed Time:15.81 s\n",
      "## Epoch 61 ==> Train Loss:0.03506, Train Acc:98.67, Test Loss:0.06718, Test Acc:97.92, Elapsed Time:15.76 s\n",
      "## Epoch 62 ==> Train Loss:0.03363, Train Acc:98.85, Test Loss:0.05741, Test Acc:98.05, Elapsed Time:15.56 s\n",
      "## Epoch 63 ==> Train Loss:0.03208, Train Acc:98.73, Test Loss:0.07009, Test Acc:97.53, Elapsed Time:15.62 s\n",
      "## Epoch 64 ==> Train Loss:0.06583, Train Acc:98.71, Test Loss:0.06460, Test Acc:97.01, Elapsed Time:15.61 s\n",
      "## Epoch 65 ==> Train Loss:0.03020, Train Acc:98.90, Test Loss:0.05919, Test Acc:97.53, Elapsed Time:15.67 s\n",
      "## Epoch 66 ==> Train Loss:0.02490, Train Acc:99.32, Test Loss:0.04668, Test Acc:98.31, Elapsed Time:15.80 s\n",
      "## Epoch 67 ==> Train Loss:0.02642, Train Acc:99.29, Test Loss:0.05046, Test Acc:98.57, Elapsed Time:15.74 s\n",
      "## Epoch 68 ==> Train Loss:0.02642, Train Acc:99.33, Test Loss:0.04416, Test Acc:98.70, Elapsed Time:15.42 s\n",
      "## Epoch 69 ==> Train Loss:0.03037, Train Acc:98.94, Test Loss:0.05982, Test Acc:98.31, Elapsed Time:15.93 s\n",
      "## Epoch 70 ==> Train Loss:0.01769, Train Acc:99.43, Test Loss:0.06375, Test Acc:98.18, Elapsed Time:15.78 s\n",
      "## Epoch 71 ==> Train Loss:0.01309, Train Acc:99.55, Test Loss:0.05333, Test Acc:98.44, Elapsed Time:16.34 s\n",
      "## Epoch 72 ==> Train Loss:0.00874, Train Acc:99.72, Test Loss:0.03568, Test Acc:99.09, Elapsed Time:15.68 s\n",
      "## Epoch 73 ==> Train Loss:0.01206, Train Acc:99.49, Test Loss:0.04887, Test Acc:98.70, Elapsed Time:15.66 s\n",
      "## Epoch 74 ==> Train Loss:0.02993, Train Acc:99.20, Test Loss:0.05490, Test Acc:98.70, Elapsed Time:15.43 s\n",
      "## Epoch 75 ==> Train Loss:0.01715, Train Acc:99.36, Test Loss:0.05041, Test Acc:98.96, Elapsed Time:15.23 s\n",
      "## Epoch 76 ==> Train Loss:0.03824, Train Acc:99.10, Test Loss:0.07906, Test Acc:98.44, Elapsed Time:15.18 s\n",
      "## Epoch 77 ==> Train Loss:0.02225, Train Acc:99.09, Test Loss:0.07487, Test Acc:98.18, Elapsed Time:15.76 s\n",
      "## Epoch 78 ==> Train Loss:0.01220, Train Acc:99.60, Test Loss:0.04626, Test Acc:98.70, Elapsed Time:15.74 s\n",
      "## Epoch 79 ==> Train Loss:0.01865, Train Acc:99.30, Test Loss:0.04295, Test Acc:98.70, Elapsed Time:15.30 s\n",
      "## Epoch 80 ==> Train Loss:0.03045, Train Acc:98.88, Test Loss:0.08507, Test Acc:98.05, Elapsed Time:16.17 s\n",
      "## Epoch 81 ==> Train Loss:0.01726, Train Acc:99.22, Test Loss:0.07754, Test Acc:98.31, Elapsed Time:15.36 s\n",
      "## Epoch 82 ==> Train Loss:0.02589, Train Acc:99.37, Test Loss:0.18489, Test Acc:96.49, Elapsed Time:15.46 s\n",
      "## Epoch 83 ==> Train Loss:0.02238, Train Acc:98.95, Test Loss:0.13857, Test Acc:97.14, Elapsed Time:15.33 s\n",
      "## Epoch 84 ==> Train Loss:0.03553, Train Acc:98.69, Test Loss:0.12696, Test Acc:96.88, Elapsed Time:15.64 s\n",
      "## Epoch 85 ==> Train Loss:0.04554, Train Acc:98.63, Test Loss:0.08841, Test Acc:97.66, Elapsed Time:15.40 s\n",
      "## Epoch 86 ==> Train Loss:0.05673, Train Acc:98.00, Test Loss:0.14154, Test Acc:96.62, Elapsed Time:15.38 s\n",
      "## Epoch 87 ==> Train Loss:0.03122, Train Acc:98.67, Test Loss:0.09817, Test Acc:97.01, Elapsed Time:15.46 s\n",
      "## Epoch 88 ==> Train Loss:0.04516, Train Acc:98.25, Test Loss:0.09411, Test Acc:97.53, Elapsed Time:15.75 s\n",
      "## Epoch 89 ==> Train Loss:0.04014, Train Acc:98.69, Test Loss:0.08109, Test Acc:97.14, Elapsed Time:15.67 s\n",
      "## Epoch 90 ==> Train Loss:0.03392, Train Acc:99.10, Test Loss:0.07050, Test Acc:97.66, Elapsed Time:15.82 s\n",
      "## Epoch 91 ==> Train Loss:0.02037, Train Acc:99.44, Test Loss:0.08535, Test Acc:97.40, Elapsed Time:15.31 s\n",
      "## Epoch 92 ==> Train Loss:0.01705, Train Acc:99.46, Test Loss:0.06630, Test Acc:98.05, Elapsed Time:15.14 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "snapshot_path = './snapshot/'\n",
    "model_name = 'CCGNet_OB'\n",
    "dataset_name = 'CB'\n",
    "History = {}\n",
    "History['test_acc'] = []\n",
    "History['val_acc'] = []\n",
    "for fold in ['fold-{}'.format(i) for i in range(10)]:\n",
    "    print('\\n################ {} ################'.format(fold))\n",
    "    train_data, valid_data, test_data = data.split(train_samples=fold_10[fold]['train'], test_samples=fold_10[fold]['valid'], val=True, val_samples=fold_10['test'])\n",
    "    tf.reset_default_graph()\n",
    "    model = CCGNet()\n",
    "    model = exp.Model(model, train_data, valid_data, val=True, val_data=test_data, snapshot_path=snapshot_path, use_subgraph=True,\n",
    "                      model_name=model_name, dataset_name='/time_{}'.format(fold[-1]))\n",
    "    history = model.fit(save_info=True, save_att=True, silence=0, train_batch_size=256,\n",
    "                        metric='acc')\n",
    "    History['test_acc'].append(max(history['test_acc']))\n",
    "    History['val_acc'].append(history['val_acc'])\n",
    "print('test_mean_acc:{:.4f}(+-{:.4f})'.format(np.array(History['test_acc']).mean()*100,np.array(History['test_acc']).std()*100))\n",
    "print('val_mean_acc:{:.4f}(+-{:.4f})'.format(np.array(History['val_acc']).mean()*100,np.array(History['val_acc']).std()*100))\n",
    "end = time.time()\n",
    "time_gap = end-start\n",
    "h = time_gap//3600\n",
    "h_m = time_gap%3600\n",
    "m = h_m//60\n",
    "s = h_m%60\n",
    "print('{}h {}m {}s'.format(int(h),int(m),round(s,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Nacc</th>\n",
       "      <th>Pacc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>97.7570(±0.9922)</td>\n",
       "      <td>95.7230(±1.9480)</td>\n",
       "      <td>99.7910(±0.0985)</td>\n",
       "      <td>99.3772(±0.2780)</td>\n",
       "      <td>99.7910(±0.0985)</td>\n",
       "      <td>99.2724(±0.2857)</td>\n",
       "      <td>99.2677(±0.4355)</td>\n",
       "      <td>99.5835(±0.1623)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Balanced Accuracy              Nacc              Pacc         Precision  \\\n",
       "CB  97.7570(±0.9922)  95.7230(±1.9480)  99.7910(±0.0985)  99.3772(±0.2780)   \n",
       "\n",
       "              Recall     Test Accuracy    Train Accuracy          f1_score  \n",
       "CB  99.7910(±0.0985)  99.2724(±0.2857)  99.2677(±0.4355)  99.5835(±0.1623)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ccgnet.MetricsReport import model_metrics_report\n",
    "\n",
    "snapshot_path = './snapshot/'\n",
    "model_metrics_report('{}/{}/'.format(snapshot_path, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parselog import ParseTestLog, ParseTestLogEnsemble\n",
    "import glob\n",
    "\n",
    "val_list = glob.glob('{}/{}/{}/*/*val*'.format(snapshot_path, model_name, 'CB'))\n",
    "l = []\n",
    "for i in val_list:\n",
    "    l.append(ParseTestLog(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####### Nico ########\n",
      "BACC: 95.71(±3.50)\n",
      "PACC: 100.00(±0.00)\n",
      "NACC: 91.43(±7.00)\n",
      "######### Bagging ########\n",
      "BACC: 96.43\n",
      "PACC: 100.00\n",
      "NACC: 92.86\n",
      "\n",
      "####### Carb ########\n",
      "BACC: 95.00(±5.45)\n",
      "PACC: 100.00(±0.00)\n",
      "NACC: 90.00(±10.90)\n",
      "######### Bagging ########\n",
      "BACC: 100.00\n",
      "PACC: 100.00\n",
      "NACC: 100.00\n",
      "\n",
      "####### Indo ########\n",
      "BACC: 90.59(±4.32)\n",
      "PACC: 100.00(±0.00)\n",
      "NACC: 81.18(±8.65)\n",
      "######### Bagging ########\n",
      "BACC: 88.24\n",
      "PACC: 100.00\n",
      "NACC: 76.47\n",
      "\n",
      "####### Para ########\n",
      "BACC: 98.75(±2.50)\n",
      "PACC: 100.00(±0.00)\n",
      "NACC: 97.50(±5.00)\n",
      "######### Bagging ########\n",
      "BACC: 100.00\n",
      "PACC: 100.00\n",
      "NACC: 100.00\n",
      "\n",
      "####### Pyre ########\n",
      "BACC: 99.74(±0.40)\n",
      "PACC: 99.47(±0.80)\n",
      "NACC: 100.00(±0.00)\n",
      "######### Bagging ########\n",
      "BACC: 100.00\n",
      "PACC: 100.00\n",
      "NACC: 100.00\n"
     ]
    }
   ],
   "source": [
    "from parselog import TestAccForEachMol\n",
    "\n",
    "nico = eval(open('./data/Nicotinamide_Test.list').read())\n",
    "carb = eval(open('./data/Carbamazepine_Test.list').read())\n",
    "indo = eval(open('./data/Indomethacin_Test.list').read())\n",
    "para = eval(open('./data/Paracetamol_Test.list').read())\n",
    "pyre = eval(open('./data/Pyrene_Test.list.old').read())\n",
    "print('\\n####### Nico ########')\n",
    "TestAccForEachMol(nico, val_list)\n",
    "print('\\n####### Carb ########')\n",
    "TestAccForEachMol(carb, val_list)\n",
    "print('\\n####### Indo ########')\n",
    "TestAccForEachMol(indo, val_list)\n",
    "print('\\n####### Para ########')\n",
    "TestAccForEachMol(para, val_list)\n",
    "print('\\n####### Pyre ########')\n",
    "TestAccForEachMol(pyre, val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(CCDC)",
   "language": "python",
   "name": "ccdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
